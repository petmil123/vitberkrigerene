{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The transformer model for sequence prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning is all about *learning* useful *functions* from big *datasets*. These useful functions are called nevral networks, and are put together from smaller functions with parameters that are decided through optimization. In opposition to conventional programming, where we tell the computer what to do, nevral networks learns from observational data and figure out its own solution to the given problem. Here we will implement the transformer model, one of the main components in big languagemodels like *ChatGPT*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.0** Structure of the datasets and the transformermodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** Let          $a = 15$, $b = 7$, $c = 47$, $d = 152$\n",
    "\n",
    "then we have   $[1, 5, 7, 4, 7, 1, 5]$, $y =[1, 5, 2]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** Let   \n",
    "\n",
    "$x^{(0)} = [1, 5, 7, 4, 7]$\n",
    "\n",
    "$x^{(1)} = [1, 5, 7, 4, 7, \\hat{z_4}]$\n",
    "\n",
    "$x^{(2)} = [1, 5, 7, 4, 7, \\hat{z_4}, \\hat{z_5}]$\n",
    "\n",
    "$x^{(3)} = [1, 5, 7, 4, 7, \\hat{z_4}, \\hat{z_5}, \\hat{z_6}]$\n",
    "\n",
    "$f_{\\theta}(x^{(0)}) = [\\hat{z_0^{(0)}}, \\hat{z_1^{(0)}}, \\hat{z_2^{(0)}}, \\hat{z_3^{(0)}}, \\hat{z_4^{(0)}}]$\n",
    "\n",
    "$f_{\\theta}(x^{(0)}) = [\\hat{z_0^{(1)}}, \\hat{z_1^{(1)}}, \\hat{z_2^{(1)}}, \\hat{z_3^{(1)}}, \\hat{z_4^{(1)}}, \\hat{z_5^{(1)}}]$\n",
    "\n",
    "$f_{\\theta}(x^{(0)}) = [\\hat{z_0^{(2)}}, \\hat{z_1^{(2)}}, \\hat{z_2^{(2)}}, \\hat{z_3^{(2)}}, \\hat{z_4^{(2)}}, \\hat{z_5^{(2)}}, \\hat{z_6^{(2)}}]$\n",
    "\n",
    "If the optimization is good, the result should be:\n",
    "\n",
    "$\\hat{z_4^{(0)}} = 1, \\hat{z_5^{(1)}} = 5$ og $\\hat{z_6^{(2)}} = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3)**\n",
    "\n",
    "For the object function to be $\\mathcal{L}(\\theta, \\mathcal{D}) = 0$, the probability distribution must be given by:\n",
    "\n",
    "$\\hat{Y} = onehot(y) = \\begin{bmatrix}\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "In this case $\\hat{y}$ will be given by:\n",
    "\n",
    "$\\hat{y} := argmax(\\hat{Y}) = y$\n",
    "\n",
    "Then, $\\mathcal(L) = 0$ will be fulfilled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4)**\n",
    "\n",
    "The number of parameters is given by:\n",
    "\n",
    "$d(2m + n_{max} + L(4k + 2p))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5)**\n",
    "\n",
    "$X = onehot(x) = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "1\n",
    "\\end{bmatrix}, z_0 = W_Ex + [W_P]_{0:n} = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & \\alpha\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "0 \\\\\n",
    "1\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "1 \\\\\n",
    "0\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\alpha\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "1 \\\\\n",
    "0\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "\\alpha\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$Z = softmax(\\begin{bmatrix}\n",
    "1\n",
    "\\alpha\n",
    "\\end{bmatrix}) = \\begin{bmatrix}\n",
    "\\frac{e^1}{e^1+1^{\\alpha}} \\\\\n",
    "\\frac{e^{\\alpha}}{e^1+e^{\\alpha}}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\hat{z} = 1 \\Rightarrow \\alpha > 1$ (when $\\alpha=1$, undefined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.0** Implementing the transformermodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** \n",
    "\n",
    "1) If the type of layer is identified as `LinearLayer` or `Attention`, `NeuralNetwork` will inherit `step_gd` from the `Layer` class. \n",
    "\n",
    "2) If the type of layer is identified as `EmbedPosition`, `NeuralNetwork` will inherit `step_gd` from the `EmbedPosition` class. \n",
    "\n",
    "3) If the type of layer is identified as `FeedForward`, `NeuralNetwork` will inherit `step_gd` from the `FeedForward` class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import *\n",
    "from layers import *\n",
    "from training import trainModel\n",
    "import numpy as np\n",
    "from data_generators import get_train_test_addition, get_train_test_sorting\n",
    "from training import *\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 5\n",
    "m = 2\n",
    "batchSize = 250\n",
    "batches = 10\n",
    "d = 10\n",
    "k = 5\n",
    "p = 15\n",
    "L = 2\n",
    "n_max = 2*r-1\n",
    "sigma = Relu\n",
    "\n",
    "data = get_train_test_sorting(r,m,batchSize, batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = EmbedPosition(n_max,m,d)\n",
    "un_embed = LinearLayer(d,m)\n",
    "softmax = Softmax()\n",
    "loss = CrossEntropy()\n",
    "\n",
    "att_ffd_list = []\n",
    "for layer in range(L):\n",
    "    att = Attention(d,k)\n",
    "    ff = FeedForward(d,p)\n",
    "    att_ffd_list.append(att)\n",
    "    att_ffd_list.append(ff)\n",
    "\n",
    "layers = [embed] + att_ffd_list + [un_embed] + [softmax]\n",
    "nn = NeuralNetwork(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterasjon  0  L =  0.6046926985748596 \n",
      "Iterasjon  1  L =  0.49801911377953906 \n",
      "Iterasjon  2  L =  0.43948746565609637 \n",
      "Iterasjon  3  L =  0.40947410475133345 \n",
      "Iterasjon  4  L =  0.38332806004625847 \n",
      "Iterasjon  5  L =  0.3515574405690137 \n",
      "Iterasjon  6  L =  0.3193117206256091 \n",
      "Iterasjon  7  L =  0.31121071436912584 \n",
      "Iterasjon  8  L =  0.3101651232492624 \n",
      "Iterasjon  9  L =  0.30950412245753367 \n",
      "Iterasjon  10  L =  0.3093691368499022 \n",
      "Iterasjon  11  L =  0.30889027358656695 \n",
      "Iterasjon  12  L =  0.30845554358385374 \n",
      "Iterasjon  13  L =  0.3081874923249515 \n",
      "Iterasjon  14  L =  0.3080559940166335 \n",
      "Iterasjon  15  L =  0.30797661109480085 \n",
      "Iterasjon  16  L =  0.30791050773803547 \n",
      "Iterasjon  17  L =  0.30788247376032657 \n",
      "Iterasjon  18  L =  0.3078496047361677 \n",
      "Iterasjon  19  L =  0.30783263600469113 \n",
      "Iterasjon  20  L =  0.30781044867617663 \n",
      "Iterasjon  21  L =  0.3078028521151273 \n",
      "Iterasjon  22  L =  0.30778956012321446 \n",
      "Iterasjon  23  L =  0.30777026286586906 \n",
      "Iterasjon  24  L =  0.30774998895760597 \n",
      "Iterasjon  25  L =  0.3077280483131559 \n",
      "Iterasjon  26  L =  0.307718534209264 \n",
      "Iterasjon  27  L =  0.3077044507844107 \n",
      "Iterasjon  28  L =  0.3077084966212517 \n",
      "Iterasjon  29  L =  0.3077008537002114 \n",
      "Iterasjon  30  L =  0.3076936672508526 \n",
      "Iterasjon  31  L =  0.307685621584954 \n",
      "Iterasjon  32  L =  0.30767469998052693 \n",
      "Iterasjon  33  L =  0.3076630608699644 \n",
      "Iterasjon  34  L =  0.30765767923623033 \n",
      "Iterasjon  35  L =  0.307650431854111 \n",
      "Iterasjon  36  L =  0.3076417863385189 \n",
      "Iterasjon  37  L =  0.30764174214195045 \n",
      "Iterasjon  38  L =  0.30764184300603414 \n",
      "Iterasjon  39  L =  0.30763044379653603 \n",
      "Iterasjon  40  L =  0.30763468590853094 \n",
      "Iterasjon  41  L =  0.3076323228078296 \n",
      "Iterasjon  42  L =  0.30762227851560514 \n",
      "Iterasjon  43  L =  0.3076193485404931 \n",
      "Iterasjon  44  L =  0.30761469385940077 \n",
      "Iterasjon  45  L =  0.30760768086244505 \n",
      "Iterasjon  46  L =  0.30760833116039504 \n",
      "Iterasjon  47  L =  0.30760605186366463 \n",
      "Iterasjon  48  L =  0.3076098048981839 \n",
      "Iterasjon  49  L =  0.3075996374788278 \n",
      "Iterasjon  50  L =  0.3076091908535943 \n",
      "Iterasjon  51  L =  0.3075888130873557 \n",
      "Iterasjon  52  L =  0.30759893207896694 \n",
      "Iterasjon  53  L =  0.3075886557454393 \n",
      "Iterasjon  54  L =  0.30758470662418885 \n",
      "Iterasjon  55  L =  0.3075707089015962 \n",
      "Iterasjon  56  L =  0.3075928776362817 \n",
      "Iterasjon  57  L =  0.3075413691553236 \n",
      "Iterasjon  58  L =  0.3075586447495344 \n",
      "Iterasjon  59  L =  0.3075502149128667 \n",
      "Iterasjon  60  L =  0.3075753752267342 \n",
      "Iterasjon  61  L =  0.3075493838694087 \n",
      "Iterasjon  62  L =  0.30758671952890393 \n",
      "Iterasjon  63  L =  0.307530824814639 \n",
      "Iterasjon  64  L =  0.307559854438355 \n",
      "Iterasjon  65  L =  0.3075440549896037 \n",
      "Iterasjon  66  L =  0.30760965152621295 \n",
      "Iterasjon  67  L =  0.3075207552314926 \n",
      "Iterasjon  68  L =  0.30756123529151974 \n",
      "Iterasjon  69  L =  0.30752087347962437 \n",
      "Iterasjon  70  L =  0.3075746742506513 \n",
      "Iterasjon  71  L =  0.30750472438296506 \n",
      "Iterasjon  72  L =  0.3075382269437491 \n",
      "Iterasjon  73  L =  0.3075341548434599 \n",
      "Iterasjon  74  L =  0.3076084905147708 \n",
      "Iterasjon  75  L =  0.30751466222122664 \n",
      "Iterasjon  76  L =  0.30755852353658225 \n",
      "Iterasjon  77  L =  0.3075271296548903 \n",
      "Iterasjon  78  L =  0.30752850735136705 \n",
      "Iterasjon  79  L =  0.30751407627281696 \n",
      "Iterasjon  80  L =  0.3075106500950643 \n",
      "Iterasjon  81  L =  0.30748373742372687 \n",
      "Iterasjon  82  L =  0.30750320660345193 \n",
      "Iterasjon  83  L =  0.3074771638055333 \n",
      "Iterasjon  84  L =  0.30749741439980377 \n",
      "Iterasjon  85  L =  0.3074898449898881 \n",
      "Iterasjon  86  L =  0.3074935284878849 \n",
      "Iterasjon  87  L =  0.3074891419602212 \n",
      "Iterasjon  88  L =  0.3074993330988513 \n",
      "Iterasjon  89  L =  0.307490268077725 \n",
      "Iterasjon  90  L =  0.30748051931981973 \n",
      "Iterasjon  91  L =  0.30748155079183437 \n",
      "Iterasjon  92  L =  0.30749330302269423 \n",
      "Iterasjon  93  L =  0.3074945000498607 \n",
      "Iterasjon  94  L =  0.3074745532261382 \n",
      "Iterasjon  95  L =  0.30749792197480086 \n",
      "Iterasjon  96  L =  0.30748477359556764 \n",
      "Iterasjon  97  L =  0.307477177114223 \n",
      "Iterasjon  98  L =  0.30748392851609513 \n",
      "Iterasjon  99  L =  0.30748973381014266 \n",
      "Iterasjon  100  L =  0.3074709015247395 \n",
      "Iterasjon  101  L =  0.3074726513340956 \n",
      "Iterasjon  102  L =  0.30746323247288343 \n",
      "Iterasjon  103  L =  0.3074622463475165 \n",
      "Iterasjon  104  L =  0.3075335940976035 \n",
      "Iterasjon  105  L =  0.3074722650237606 \n",
      "Iterasjon  106  L =  0.30749988991325367 \n",
      "Iterasjon  107  L =  0.3074885022059919 \n",
      "Iterasjon  108  L =  0.30748859526671 \n",
      "Iterasjon  109  L =  0.30747709435344694 \n",
      "Iterasjon  110  L =  0.3074634842897782 \n",
      "Iterasjon  111  L =  0.3074608121474548 \n",
      "Iterasjon  112  L =  0.3074543426668615 \n",
      "Iterasjon  113  L =  0.3074635274676182 \n",
      "Iterasjon  114  L =  0.30745740344801364 \n",
      "Iterasjon  115  L =  0.30748450595892884 \n",
      "Iterasjon  116  L =  0.3074393782174957 \n",
      "Iterasjon  117  L =  0.30749467035461386 \n",
      "Iterasjon  118  L =  0.30746239261784636 \n",
      "Iterasjon  119  L =  0.3074703658712555 \n",
      "Iterasjon  120  L =  0.3074589387837649 \n",
      "Iterasjon  121  L =  0.3074973374216582 \n",
      "Iterasjon  122  L =  0.3074329498585685 \n",
      "Iterasjon  123  L =  0.30746111034719537 \n",
      "Iterasjon  124  L =  0.3074737754866693 \n",
      "Iterasjon  125  L =  0.30744549910084606 \n",
      "Iterasjon  126  L =  0.30748297282431303 \n",
      "Iterasjon  127  L =  0.30743809632151176 \n",
      "Iterasjon  128  L =  0.30750988299572823 \n",
      "Iterasjon  129  L =  0.3074237156111518 \n",
      "Iterasjon  130  L =  0.3074521670336575 \n",
      "Iterasjon  131  L =  0.3074613207611629 \n",
      "Iterasjon  132  L =  0.30742419376132407 \n",
      "Iterasjon  133  L =  0.3074489186969037 \n",
      "Iterasjon  134  L =  0.3074324718335178 \n",
      "Iterasjon  135  L =  0.3074447959657879 \n",
      "Iterasjon  136  L =  0.30743817442559684 \n",
      "Iterasjon  137  L =  0.30743387677452116 \n",
      "Iterasjon  138  L =  0.3074422042405053 \n",
      "Iterasjon  139  L =  0.30742590607379405 \n",
      "Iterasjon  140  L =  0.30746555603531733 \n",
      "Iterasjon  141  L =  0.3074258152710736 \n",
      "Iterasjon  142  L =  0.30775621316337015 \n",
      "Iterasjon  143  L =  0.3075818085892394 \n",
      "Iterasjon  144  L =  0.3075402156448081 \n",
      "Iterasjon  145  L =  0.30753654413922243 \n",
      "Iterasjon  146  L =  0.30750806379464296 \n",
      "Iterasjon  147  L =  0.30750191298564955 \n",
      "Iterasjon  148  L =  0.3074906227485285 \n",
      "Iterasjon  149  L =  0.30749474040500735 \n",
      "Iterasjon  150  L =  0.30748590165521544 \n",
      "Iterasjon  151  L =  0.3074928528185368 \n",
      "Iterasjon  152  L =  0.3074795957299322 \n",
      "Iterasjon  153  L =  0.30748496983979356 \n",
      "Iterasjon  154  L =  0.3074694320733097 \n",
      "Iterasjon  155  L =  0.3074786903853778 \n",
      "Iterasjon  156  L =  0.3074611749714377 \n",
      "Iterasjon  157  L =  0.30748330107339783 \n",
      "Iterasjon  158  L =  0.30746414402840105 \n",
      "Iterasjon  159  L =  0.30746516517937733 \n",
      "Iterasjon  160  L =  0.30745298988356373 \n",
      "Iterasjon  161  L =  0.3074691923094533 \n",
      "Iterasjon  162  L =  0.30745386546543746 \n",
      "Iterasjon  163  L =  0.3074546157018164 \n",
      "Iterasjon  164  L =  0.30744542703725797 \n",
      "Iterasjon  165  L =  0.3074567571450338 \n",
      "Iterasjon  166  L =  0.30743729845818946 \n",
      "Iterasjon  167  L =  0.3074605068090714 \n",
      "Iterasjon  168  L =  0.3074305852159258 \n",
      "Iterasjon  169  L =  0.30746221590983136 \n",
      "Iterasjon  170  L =  0.30742539399749486 \n",
      "Iterasjon  171  L =  0.30745570919399995 \n",
      "Iterasjon  172  L =  0.30741583525843025 \n",
      "Iterasjon  173  L =  0.30746794651301 \n",
      "Iterasjon  174  L =  0.3074167963982559 \n",
      "Iterasjon  175  L =  0.30744915618361407 \n",
      "Iterasjon  176  L =  0.30741816438506686 \n",
      "Iterasjon  177  L =  0.30744411251530146 \n",
      "Iterasjon  178  L =  0.30740294665600376 \n",
      "Iterasjon  179  L =  0.3074508177765412 \n",
      "Iterasjon  180  L =  0.3074012131184882 \n",
      "Iterasjon  181  L =  0.30742887880692515 \n",
      "Iterasjon  182  L =  0.30739811822937446 \n",
      "Iterasjon  183  L =  0.30742934334852257 \n",
      "Iterasjon  184  L =  0.30739595236241896 \n",
      "Iterasjon  185  L =  0.3074236955922939 \n",
      "Iterasjon  186  L =  0.30739137854461734 \n",
      "Iterasjon  187  L =  0.30744176653248634 \n",
      "Iterasjon  188  L =  0.3073910122578494 \n",
      "Iterasjon  189  L =  0.30741097735964973 \n",
      "Iterasjon  190  L =  0.3073869635207294 \n",
      "Iterasjon  191  L =  0.3073917051700332 \n",
      "Iterasjon  192  L =  0.3074027168588236 \n",
      "Iterasjon  193  L =  0.3073801404968754 \n",
      "Iterasjon  194  L =  0.3074102930794854 \n",
      "Iterasjon  195  L =  0.30737214902219684 \n",
      "Iterasjon  196  L =  0.3074093249713411 \n",
      "Iterasjon  197  L =  0.30736902553998957 \n",
      "Iterasjon  198  L =  0.3073833569699071 \n",
      "Iterasjon  199  L =  0.3073807380804922 \n",
      "Iterasjon  200  L =  0.3073717082342705 \n",
      "Iterasjon  201  L =  0.307374404755299 \n",
      "Iterasjon  202  L =  0.3073856552576615 \n",
      "Iterasjon  203  L =  0.30735548481335007 \n",
      "Iterasjon  204  L =  0.3073910400657611 \n",
      "Iterasjon  205  L =  0.3073594125334374 \n",
      "Iterasjon  206  L =  0.3073798661407911 \n",
      "Iterasjon  207  L =  0.30737080503833025 \n",
      "Iterasjon  208  L =  0.3073605169104233 \n",
      "Iterasjon  209  L =  0.3073775347817925 \n",
      "Iterasjon  210  L =  0.3073500711488644 \n",
      "Iterasjon  211  L =  0.3073899354992532 \n",
      "Iterasjon  212  L =  0.3073499247981029 \n",
      "Iterasjon  213  L =  0.3073735904834002 \n",
      "Iterasjon  214  L =  0.30736078301433883 \n",
      "Iterasjon  215  L =  0.30736024338053886 \n",
      "Iterasjon  216  L =  0.3073600407833452 \n",
      "Iterasjon  217  L =  0.30735575772895257 \n",
      "Iterasjon  218  L =  0.30738349113830027 \n",
      "Iterasjon  219  L =  0.3073498178544344 \n",
      "Iterasjon  220  L =  0.30738664348243505 \n",
      "Iterasjon  221  L =  0.30734872363619986 \n",
      "Iterasjon  222  L =  0.30735800517420925 \n",
      "Iterasjon  223  L =  0.3073659537150069 \n",
      "Iterasjon  224  L =  0.3073543501896515 \n",
      "Iterasjon  225  L =  0.30735884753477116 \n",
      "Iterasjon  226  L =  0.3073535949324534 \n",
      "Iterasjon  227  L =  0.30736216756305057 \n",
      "Iterasjon  228  L =  0.3073526061699502 \n",
      "Iterasjon  229  L =  0.30736107946877167 \n",
      "Iterasjon  230  L =  0.3073473248705133 \n",
      "Iterasjon  231  L =  0.30735841054436025 \n",
      "Iterasjon  232  L =  0.30736053823481346 \n",
      "Iterasjon  233  L =  0.307340931137073 \n",
      "Iterasjon  234  L =  0.30736041346785853 \n",
      "Iterasjon  235  L =  0.3073416891121738 \n",
      "Iterasjon  236  L =  0.3073571240759113 \n",
      "Iterasjon  237  L =  0.3073455165892761 \n",
      "Iterasjon  238  L =  0.30734730102862284 \n",
      "Iterasjon  239  L =  0.3073604171832357 \n",
      "Iterasjon  240  L =  0.30733903572030363 \n",
      "Iterasjon  241  L =  0.30735479678751043 \n",
      "Iterasjon  242  L =  0.3073466384279763 \n",
      "Iterasjon  243  L =  0.30734193814515115 \n",
      "Iterasjon  244  L =  0.3073480177000953 \n",
      "Iterasjon  245  L =  0.3073396187511412 \n",
      "Iterasjon  246  L =  0.30734416762872396 \n",
      "Iterasjon  247  L =  0.3073342255237467 \n",
      "Iterasjon  248  L =  0.30736911899035346 \n",
      "Iterasjon  249  L =  0.30733793802054576 \n",
      "Iterasjon  250  L =  0.3073559179773001 \n",
      "Iterasjon  251  L =  0.3073607250081815 \n",
      "Iterasjon  252  L =  0.3073319662806566 \n",
      "Iterasjon  253  L =  0.3073706954774649 \n",
      "Iterasjon  254  L =  0.30733393650910407 \n",
      "Iterasjon  255  L =  0.3073493025451324 \n",
      "Iterasjon  256  L =  0.3073360778325666 \n",
      "Iterasjon  257  L =  0.30733712867871865 \n",
      "Iterasjon  258  L =  0.30734268205549375 \n",
      "Iterasjon  259  L =  0.30733610240162357 \n",
      "Iterasjon  260  L =  0.3073447991464101 \n",
      "Iterasjon  261  L =  0.3073364236731809 \n",
      "Iterasjon  262  L =  0.30733704140368256 \n",
      "Iterasjon  263  L =  0.30734062023205433 \n",
      "Iterasjon  264  L =  0.30733685232717917 \n",
      "Iterasjon  265  L =  0.30733971531228615 \n",
      "Iterasjon  266  L =  0.3073324765622944 \n",
      "Iterasjon  267  L =  0.30734012259969096 \n",
      "Iterasjon  268  L =  0.3073391715476526 \n",
      "Iterasjon  269  L =  0.30733865948793865 \n",
      "Iterasjon  270  L =  0.3073538699048545 \n",
      "Iterasjon  271  L =  0.3073289857804716 \n",
      "Iterasjon  272  L =  0.30734814390742826 \n",
      "Iterasjon  273  L =  0.3073326455648816 \n",
      "Iterasjon  274  L =  0.3073289145938811 \n",
      "Iterasjon  275  L =  0.3073407683208455 \n",
      "Iterasjon  276  L =  0.30735473837685623 \n",
      "Iterasjon  277  L =  0.3073455366869427 \n",
      "Iterasjon  278  L =  0.307365002856962 \n",
      "Iterasjon  279  L =  0.3073441274456396 \n",
      "Iterasjon  280  L =  0.3073430403675035 \n",
      "Iterasjon  281  L =  0.30733823561623963 \n",
      "Iterasjon  282  L =  0.30733523419238395 \n",
      "Iterasjon  283  L =  0.3073322921821754 \n",
      "Iterasjon  284  L =  0.3073269518396574 \n",
      "Iterasjon  285  L =  0.30733000698712765 \n",
      "Iterasjon  286  L =  0.30732917782020774 \n",
      "Iterasjon  287  L =  0.3073286454275218 \n",
      "Iterasjon  288  L =  0.3073327647417847 \n",
      "Iterasjon  289  L =  0.3073290084857708 \n",
      "Iterasjon  290  L =  0.3073284170898493 \n",
      "Iterasjon  291  L =  0.30732232999953857 \n",
      "Iterasjon  292  L =  0.30732472616536133 \n",
      "Iterasjon  293  L =  0.30733376187037587 \n",
      "Iterasjon  294  L =  0.30731705720890273 \n",
      "Iterasjon  295  L =  0.3073241670512211 \n",
      "Iterasjon  296  L =  0.3073269158788704 \n",
      "Iterasjon  297  L =  0.307328426025147 \n",
      "Iterasjon  298  L =  0.3073268408159086 \n",
      "Iterasjon  299  L =  0.30732621520204406 \n"
     ]
    }
   ],
   "source": [
    "losses = trainModel(nn,data,300,loss, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DO NOT RUN IF NOT NEW TRAINED MODEL\n",
    "# with open(\"sortingTrained_v1\", 'wb') as f:\n",
    "#     pickle.dump(nn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_network.NeuralNetwork"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"savedObject\", 'rb') as f:\n",
    "     nn2 = pickle.load(f)\n",
    "\n",
    "type(nn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(250, 5)\n",
      "(250, 5)\n",
      "1\n",
      "(250, 6)\n",
      "(250, 6)\n",
      "2\n",
      "(250, 7)\n",
      "(250, 7)\n",
      "3\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "4\n",
      "(250, 9)\n",
      "(250, 9)\n"
     ]
    }
   ],
   "source": [
    "with open(\"sortingTrained_v1\", \"rb\") as f:\n",
    "    nn = pickle.load(f)\n",
    "\n",
    "y_pred = predict(nn, data['x_test'], r, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1. 1. 0. 1. 0.]\n",
      "  [0. 1. 0. 1. 0.]\n",
      "  [1. 0. 1. 1. 1.]\n",
      "  ...\n",
      "  [1. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 1.]\n",
      "  [0. 0. 0. 1. 1.]]]\n",
      "\n",
      "[[[0. 0. 1. 1. 1.]\n",
      "  [0. 0. 0. 1. 1.]\n",
      "  [0. 1. 1. 1. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1. 1.]\n",
      "  [0. 0. 0. 1. 1.]\n",
      "  [0. 0. 0. 1. 1.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print()\n",
    "print(data['y_test'])\n",
    "np.count_nonzero(np.count_nonzero(y_pred == data['y_test'], axis=2) == y_pred.shape[-1])\n",
    "\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 7\n",
    "m = 5\n",
    "batchSize = 250\n",
    "batches = 10\n",
    "iterations = 300\n",
    "d = 20\n",
    "k = 10\n",
    "p = 25\n",
    "L = 2\n",
    "n_max = 2*r-1\n",
    "sigma = Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_train_test_sorting(r,m,batchSize, batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = EmbedPosition(n_max,m,d)\n",
    "att1 = Attention(d,k)\n",
    "ff1 = FeedForward(d,p)\n",
    "un_embed = LinearLayer(d,m)\n",
    "softmax = Softmax()\n",
    "loss = CrossEntropy()\n",
    "\n",
    "nn = NeuralNetwork([embed,att1,ff1,un_embed,softmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterasjon  0  L =  1.4944273295782693 \n",
      "Iterasjon  1  L =  1.258161980523269 \n",
      "Iterasjon  2  L =  1.2075041194257472 \n",
      "Iterasjon  3  L =  1.1789771313743267 \n",
      "Iterasjon  4  L =  1.1609216421805795 \n",
      "Iterasjon  5  L =  1.1410543004512221 \n",
      "Iterasjon  6  L =  1.1132539553655407 \n",
      "Iterasjon  7  L =  1.0747589545173892 \n",
      "Iterasjon  8  L =  1.0360798532922657 \n",
      "Iterasjon  9  L =  1.0004070711238895 \n",
      "Iterasjon  10  L =  0.9673399660441205 \n",
      "Iterasjon  11  L =  0.9349262570498654 \n",
      "Iterasjon  12  L =  0.9084424151223031 \n",
      "Iterasjon  13  L =  0.8875280956722753 \n",
      "Iterasjon  14  L =  0.8711623277260498 \n",
      "Iterasjon  15  L =  0.8582133654631935 \n",
      "Iterasjon  16  L =  0.8498469733492792 \n",
      "Iterasjon  17  L =  0.843530321822405 \n",
      "Iterasjon  18  L =  0.8359587790824647 \n",
      "Iterasjon  19  L =  0.8282925983602558 \n",
      "Iterasjon  20  L =  0.8230280246956824 \n",
      "Iterasjon  21  L =  0.8094255094587242 \n",
      "Iterasjon  22  L =  0.8012635962284435 \n",
      "Iterasjon  23  L =  0.7884111113685399 \n",
      "Iterasjon  24  L =  0.7756826969101736 \n",
      "Iterasjon  25  L =  0.7681970888103724 \n",
      "Iterasjon  26  L =  0.763320696417448 \n",
      "Iterasjon  27  L =  0.7597199579091509 \n",
      "Iterasjon  28  L =  0.7570657275350026 \n",
      "Iterasjon  29  L =  0.7548684811986274 \n",
      "Iterasjon  30  L =  0.7531066334792811 \n",
      "Iterasjon  31  L =  0.7516819309763456 \n",
      "Iterasjon  32  L =  0.7505929259497671 \n",
      "Iterasjon  33  L =  0.7495466623581867 \n",
      "Iterasjon  34  L =  0.7486550140743565 \n",
      "Iterasjon  35  L =  0.7480785472941529 \n",
      "Iterasjon  36  L =  0.7474381567609554 \n",
      "Iterasjon  37  L =  0.7469270138676242 \n",
      "Iterasjon  38  L =  0.7465618511047464 \n",
      "Iterasjon  39  L =  0.7462297346239661 \n",
      "Iterasjon  40  L =  0.7458335897933163 \n",
      "Iterasjon  41  L =  0.7456073702742666 \n",
      "Iterasjon  42  L =  0.7453834564058248 \n",
      "Iterasjon  43  L =  0.7452054203351561 \n",
      "Iterasjon  44  L =  0.745042557058692 \n",
      "Iterasjon  45  L =  0.7448481027633512 \n",
      "Iterasjon  46  L =  0.744569387462658 \n",
      "Iterasjon  47  L =  0.7443714128578669 \n",
      "Iterasjon  48  L =  0.7443132680091782 \n",
      "Iterasjon  49  L =  0.7441624183701465 \n",
      "Iterasjon  50  L =  0.7439752858642688 \n",
      "Iterasjon  51  L =  0.7437545366208365 \n",
      "Iterasjon  52  L =  0.743639237273805 \n",
      "Iterasjon  53  L =  0.7435749179115919 \n",
      "Iterasjon  54  L =  0.7435028160415535 \n",
      "Iterasjon  55  L =  0.7433917705437864 \n",
      "Iterasjon  56  L =  0.7433308089488191 \n",
      "Iterasjon  57  L =  0.743221746411359 \n",
      "Iterasjon  58  L =  0.7432319250695747 \n",
      "Iterasjon  59  L =  0.7431859328715402 \n",
      "Iterasjon  60  L =  0.7431018471578102 \n",
      "Iterasjon  61  L =  0.7430400623389221 \n",
      "Iterasjon  62  L =  0.7429534437072639 \n",
      "Iterasjon  63  L =  0.7429406677381898 \n",
      "Iterasjon  64  L =  0.7428673346415062 \n",
      "Iterasjon  65  L =  0.7427721605315437 \n",
      "Iterasjon  66  L =  0.7427372868829198 \n",
      "Iterasjon  67  L =  0.7426432379917756 \n",
      "Iterasjon  68  L =  0.7426206727225597 \n",
      "Iterasjon  69  L =  0.7425468317342567 \n",
      "Iterasjon  70  L =  0.7425153717773295 \n",
      "Iterasjon  71  L =  0.7424639787700886 \n",
      "Iterasjon  72  L =  0.7424701886271065 \n",
      "Iterasjon  73  L =  0.7423883370120368 \n",
      "Iterasjon  74  L =  0.7423711647333742 \n",
      "Iterasjon  75  L =  0.7423055676705309 \n",
      "Iterasjon  76  L =  0.7422689306699367 \n",
      "Iterasjon  77  L =  0.7422172306037582 \n",
      "Iterasjon  78  L =  0.7421776056481538 \n",
      "Iterasjon  79  L =  0.7421562706781454 \n",
      "Iterasjon  80  L =  0.7421631697020964 \n",
      "Iterasjon  81  L =  0.7421826433481493 \n",
      "Iterasjon  82  L =  0.7420664224792568 \n",
      "Iterasjon  83  L =  0.7420436219597101 \n",
      "Iterasjon  84  L =  0.7420391580500342 \n",
      "Iterasjon  85  L =  0.7420022495556283 \n",
      "Iterasjon  86  L =  0.7419369406659195 \n",
      "Iterasjon  87  L =  0.7420389781716981 \n",
      "Iterasjon  88  L =  0.7420190170171462 \n",
      "Iterasjon  89  L =  0.7419348644111061 \n",
      "Iterasjon  90  L =  0.7419459319463588 \n",
      "Iterasjon  91  L =  0.7419227915879714 \n",
      "Iterasjon  92  L =  0.7419734270942142 \n",
      "Iterasjon  93  L =  0.7420526690149576 \n",
      "Iterasjon  94  L =  0.742070202126947 \n",
      "Iterasjon  95  L =  0.7419613196059988 \n",
      "Iterasjon  96  L =  0.741907788163591 \n",
      "Iterasjon  97  L =  0.7419015169825031 \n",
      "Iterasjon  98  L =  0.7418681656142897 \n",
      "Iterasjon  99  L =  0.7419144281503226 \n",
      "Iterasjon  100  L =  0.7418595941892949 \n",
      "Iterasjon  101  L =  0.7419088188753157 \n",
      "Iterasjon  102  L =  0.7418214406370172 \n",
      "Iterasjon  103  L =  0.7418487692115672 \n",
      "Iterasjon  104  L =  0.7417864050567105 \n",
      "Iterasjon  105  L =  0.741769590260961 \n",
      "Iterasjon  106  L =  0.7418000433108564 \n",
      "Iterasjon  107  L =  0.7417647659480012 \n",
      "Iterasjon  108  L =  0.7417688059321577 \n",
      "Iterasjon  109  L =  0.741702669644459 \n",
      "Iterasjon  110  L =  0.7417197616888804 \n",
      "Iterasjon  111  L =  0.7417101759251002 \n",
      "Iterasjon  112  L =  0.7417650793360508 \n",
      "Iterasjon  113  L =  0.7417573485248505 \n",
      "Iterasjon  114  L =  0.7417424131570536 \n",
      "Iterasjon  115  L =  0.7417106963902251 \n",
      "Iterasjon  116  L =  0.7417230580180618 \n",
      "Iterasjon  117  L =  0.7417292228843411 \n",
      "Iterasjon  118  L =  0.7416456578414168 \n",
      "Iterasjon  119  L =  0.7416885398031525 \n",
      "Iterasjon  120  L =  0.7416834223837714 \n",
      "Iterasjon  121  L =  0.741690392222891 \n",
      "Iterasjon  122  L =  0.7416972811766397 \n",
      "Iterasjon  123  L =  0.7416338148959444 \n",
      "Iterasjon  124  L =  0.7416693362108412 \n",
      "Iterasjon  125  L =  0.7417255077133317 \n",
      "Iterasjon  126  L =  0.7417291853740233 \n",
      "Iterasjon  127  L =  0.7416827879199683 \n",
      "Iterasjon  128  L =  0.7416949394927527 \n",
      "Iterasjon  129  L =  0.7416394265574655 \n",
      "Iterasjon  130  L =  0.7415932936668217 \n",
      "Iterasjon  131  L =  0.7416016758667093 \n",
      "Iterasjon  132  L =  0.7415977037784622 \n",
      "Iterasjon  133  L =  0.7415685494115919 \n",
      "Iterasjon  134  L =  0.7416314317121432 \n",
      "Iterasjon  135  L =  0.7415828930090375 \n",
      "Iterasjon  136  L =  0.7416341921681298 \n",
      "Iterasjon  137  L =  0.7415646146670917 \n",
      "Iterasjon  138  L =  0.7416198856610374 \n",
      "Iterasjon  139  L =  0.7415754903167062 \n",
      "Iterasjon  140  L =  0.7416396975568051 \n",
      "Iterasjon  141  L =  0.7415942872302277 \n",
      "Iterasjon  142  L =  0.7416359315225829 \n",
      "Iterasjon  143  L =  0.7414937787704632 \n",
      "Iterasjon  144  L =  0.7415516231391044 \n",
      "Iterasjon  145  L =  0.7414908485643432 \n",
      "Iterasjon  146  L =  0.7415158466645246 \n",
      "Iterasjon  147  L =  0.7415170704807202 \n",
      "Iterasjon  148  L =  0.7414945254310326 \n",
      "Iterasjon  149  L =  0.74154150308179 \n",
      "Iterasjon  150  L =  0.7415081270073437 \n",
      "Iterasjon  151  L =  0.7414932020492218 \n",
      "Iterasjon  152  L =  0.7414692451826841 \n",
      "Iterasjon  153  L =  0.7416209038634887 \n",
      "Iterasjon  154  L =  0.7415596167493177 \n",
      "Iterasjon  155  L =  0.7416036356245984 \n",
      "Iterasjon  156  L =  0.7415063091493179 \n",
      "Iterasjon  157  L =  0.7414654835641978 \n",
      "Iterasjon  158  L =  0.7414637154101199 \n",
      "Iterasjon  159  L =  0.7414898904077918 \n",
      "Iterasjon  160  L =  0.7413545219855535 \n",
      "Iterasjon  161  L =  0.7413764230776297 \n",
      "Iterasjon  162  L =  0.7413517223725655 \n",
      "Iterasjon  163  L =  0.7413481482816169 \n",
      "Iterasjon  164  L =  0.7413883689006383 \n",
      "Iterasjon  165  L =  0.7413500376391622 \n",
      "Iterasjon  166  L =  0.741294649513032 \n",
      "Iterasjon  167  L =  0.7413354041803123 \n",
      "Iterasjon  168  L =  0.7413691289850517 \n",
      "Iterasjon  169  L =  0.7413541663639669 \n",
      "Iterasjon  170  L =  0.7413287090835426 \n",
      "Iterasjon  171  L =  0.7412432016285396 \n",
      "Iterasjon  172  L =  0.7413188635654794 \n",
      "Iterasjon  173  L =  0.7411816103181642 \n",
      "Iterasjon  174  L =  0.7411713523022757 \n",
      "Iterasjon  175  L =  0.7411818406443549 \n",
      "Iterasjon  176  L =  0.7412318560262893 \n",
      "Iterasjon  177  L =  0.7414186649188802 \n",
      "Iterasjon  178  L =  0.7413782545847437 \n",
      "Iterasjon  179  L =  0.7413905285705483 \n",
      "Iterasjon  180  L =  0.7412223759049859 \n",
      "Iterasjon  181  L =  0.7412917163693049 \n",
      "Iterasjon  182  L =  0.7412993434687918 \n",
      "Iterasjon  183  L =  0.7412616440176633 \n",
      "Iterasjon  184  L =  0.7412165484637605 \n",
      "Iterasjon  185  L =  0.7411823905963464 \n",
      "Iterasjon  186  L =  0.7412297713909137 \n",
      "Iterasjon  187  L =  0.7412822590490911 \n",
      "Iterasjon  188  L =  0.7413467278917028 \n",
      "Iterasjon  189  L =  0.741325866785877 \n",
      "Iterasjon  190  L =  0.7411011358886912 \n",
      "Iterasjon  191  L =  0.7413276851809791 \n",
      "Iterasjon  192  L =  0.7412303599901234 \n",
      "Iterasjon  193  L =  0.7410950308054527 \n",
      "Iterasjon  194  L =  0.7411762734547489 \n",
      "Iterasjon  195  L =  0.7411622754035048 \n",
      "Iterasjon  196  L =  0.7411066238377957 \n",
      "Iterasjon  197  L =  0.741211225736351 \n",
      "Iterasjon  198  L =  0.740975997049701 \n",
      "Iterasjon  199  L =  0.7410461152480788 \n",
      "Iterasjon  200  L =  0.7409771172451017 \n",
      "Iterasjon  201  L =  0.7409843620466867 \n",
      "Iterasjon  202  L =  0.7410102108754464 \n",
      "Iterasjon  203  L =  0.740982380480964 \n",
      "Iterasjon  204  L =  0.7409722042310284 \n",
      "Iterasjon  205  L =  0.7409909636926517 \n",
      "Iterasjon  206  L =  0.7409703562269507 \n",
      "Iterasjon  207  L =  0.7410209421986785 \n",
      "Iterasjon  208  L =  0.7409594537771416 \n",
      "Iterasjon  209  L =  0.7409304609739449 \n",
      "Iterasjon  210  L =  0.7408955770131551 \n",
      "Iterasjon  211  L =  0.7408910766717031 \n",
      "Iterasjon  212  L =  0.7409052686251536 \n",
      "Iterasjon  213  L =  0.7409809866333218 \n",
      "Iterasjon  214  L =  0.7409778441879447 \n",
      "Iterasjon  215  L =  0.7408391456974182 \n",
      "Iterasjon  216  L =  0.7408509216955359 \n",
      "Iterasjon  217  L =  0.7408917621789358 \n",
      "Iterasjon  218  L =  0.7410665158150991 \n",
      "Iterasjon  219  L =  0.7408922770835723 \n",
      "Iterasjon  220  L =  0.7409062515887357 \n",
      "Iterasjon  221  L =  0.7408172396714203 \n",
      "Iterasjon  222  L =  0.7409295186172095 \n",
      "Iterasjon  223  L =  0.740808550066785 \n",
      "Iterasjon  224  L =  0.7408055350891741 \n",
      "Iterasjon  225  L =  0.7410879190353671 \n",
      "Iterasjon  226  L =  0.7415993010657231 \n",
      "Iterasjon  227  L =  0.7408432402651988 \n",
      "Iterasjon  228  L =  0.740884432340673 \n",
      "Iterasjon  229  L =  0.7409162307991922 \n",
      "Iterasjon  230  L =  0.7408888050893401 \n",
      "Iterasjon  231  L =  0.7408596477813516 \n",
      "Iterasjon  232  L =  0.7408105035542737 \n",
      "Iterasjon  233  L =  0.7407842407181882 \n",
      "Iterasjon  234  L =  0.7408329149519471 \n",
      "Iterasjon  235  L =  0.7408139452169618 \n",
      "Iterasjon  236  L =  0.740894742066895 \n",
      "Iterasjon  237  L =  0.7409449950863659 \n",
      "Iterasjon  238  L =  0.7408580939208685 \n",
      "Iterasjon  239  L =  0.740823739451429 \n",
      "Iterasjon  240  L =  0.7407194536562544 \n",
      "Iterasjon  241  L =  0.7406369948853374 \n",
      "Iterasjon  242  L =  0.7406649408477562 \n",
      "Iterasjon  243  L =  0.7407505760464481 \n",
      "Iterasjon  244  L =  0.7408502354573102 \n",
      "Iterasjon  245  L =  0.7409639240226296 \n",
      "Iterasjon  246  L =  0.740817090666857 \n",
      "Iterasjon  247  L =  0.7406671095253087 \n",
      "Iterasjon  248  L =  0.7407177520991507 \n",
      "Iterasjon  249  L =  0.7407388771459206 \n",
      "Iterasjon  250  L =  0.7407735561524434 \n",
      "Iterasjon  251  L =  0.7407055748198449 \n",
      "Iterasjon  252  L =  0.7406134520021108 \n",
      "Iterasjon  253  L =  0.7405999763240245 \n",
      "Iterasjon  254  L =  0.7405321881521656 \n",
      "Iterasjon  255  L =  0.7406129551969336 \n",
      "Iterasjon  256  L =  0.7408330526652811 \n",
      "Iterasjon  257  L =  0.7408151522734677 \n",
      "Iterasjon  258  L =  0.740868436714596 \n",
      "Iterasjon  259  L =  0.7405395477845589 \n",
      "Iterasjon  260  L =  0.7405820202982482 \n",
      "Iterasjon  261  L =  0.7407678021852976 \n",
      "Iterasjon  262  L =  0.7410009000026319 \n",
      "Iterasjon  263  L =  0.7406711940183697 \n",
      "Iterasjon  264  L =  0.7405660769341058 \n",
      "Iterasjon  265  L =  0.7407940346086628 \n",
      "Iterasjon  266  L =  0.7410557763107255 \n",
      "Iterasjon  267  L =  0.7408792245071433 \n",
      "Iterasjon  268  L =  0.740768309069127 \n",
      "Iterasjon  269  L =  0.7407340178410202 \n",
      "Iterasjon  270  L =  1.3518015597073327 \n",
      "Iterasjon  271  L =  1.4547588955895336 \n",
      "Iterasjon  272  L =  1.1311564491784014 \n",
      "Iterasjon  273  L =  1.01367288986953 \n",
      "Iterasjon  274  L =  0.9337295624923982 \n",
      "Iterasjon  275  L =  0.8691306332149568 \n",
      "Iterasjon  276  L =  0.830458171775706 \n",
      "Iterasjon  277  L =  0.7985957930218287 \n",
      "Iterasjon  278  L =  0.7788958201508019 \n",
      "Iterasjon  279  L =  0.7684584454161708 \n",
      "Iterasjon  280  L =  0.7620628900024025 \n",
      "Iterasjon  281  L =  0.7581029818711651 \n",
      "Iterasjon  282  L =  0.7554710421726302 \n",
      "Iterasjon  283  L =  0.7536065843121265 \n",
      "Iterasjon  284  L =  0.7521711802634912 \n",
      "Iterasjon  285  L =  0.7511013779664758 \n",
      "Iterasjon  286  L =  0.7502763868387048 \n",
      "Iterasjon  287  L =  0.7496365118755205 \n",
      "Iterasjon  288  L =  0.7489858674020117 \n",
      "Iterasjon  289  L =  0.7484730232418185 \n",
      "Iterasjon  290  L =  0.748049195254471 \n",
      "Iterasjon  291  L =  0.7475992841777181 \n",
      "Iterasjon  292  L =  0.7472415207467974 \n",
      "Iterasjon  293  L =  0.7468562390059137 \n",
      "Iterasjon  294  L =  0.7465221253766038 \n",
      "Iterasjon  295  L =  0.7462838835473045 \n",
      "Iterasjon  296  L =  0.7460869277301077 \n",
      "Iterasjon  297  L =  0.7459694438387713 \n",
      "Iterasjon  298  L =  0.7457476815603952 \n",
      "Iterasjon  299  L =  0.7456362291588041 \n"
     ]
    }
   ],
   "source": [
    "losses = trainModel(nn,data, iterations, loss, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN IF NOT NEW TRAINED MODEL\n",
    "with open(\"sortingTrained_v2\", 'wb') as f:\n",
    "    pickle.dump(nn, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
