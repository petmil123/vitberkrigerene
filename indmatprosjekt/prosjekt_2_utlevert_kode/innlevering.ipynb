{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The transformer model for sequence prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning is all about *learning* useful *functions* from big *datasets*. These useful functions are called neural networks, and are put together from smaller functions with parameters that are decided through optimization. In opposition to conventional programming, where we tell the computer what to do, nevral networks learns from observational data and figure out its own solution to the given problem. Here we will implement the transformer model, one of the main components in big languagemodels like *ChatGPT*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.0** Structure of the datasets and the transformermodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** Let          $a = 15$, $b = 7$, $c = 47$, $d = 152$\n",
    "\n",
    "then we have   $[1, 5, 7, 4, 7, 1, 5]$, $y =[1, 5, 2]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** Let   \n",
    "\n",
    "$x^{(0)} = [1, 5, 7, 4, 7]$\n",
    "\n",
    "$x^{(1)} = [1, 5, 7, 4, 7, \\hat{z_4}]$\n",
    "\n",
    "$x^{(2)} = [1, 5, 7, 4, 7, \\hat{z_4}, \\hat{z_5}]$\n",
    "\n",
    "$x^{(3)} = [1, 5, 7, 4, 7, \\hat{z_4}, \\hat{z_5}, \\hat{z_6}]$\n",
    "\n",
    "$f_{\\theta}(x^{(0)}) = [\\hat{z_0^{(0)}}, \\hat{z_1^{(0)}}, \\hat{z_2^{(0)}}, \\hat{z_3^{(0)}}, \\hat{z_4^{(0)}}]$\n",
    "\n",
    "$f_{\\theta}(x^{(0)}) = [\\hat{z_0^{(1)}}, \\hat{z_1^{(1)}}, \\hat{z_2^{(1)}}, \\hat{z_3^{(1)}}, \\hat{z_4^{(1)}}, \\hat{z_5^{(1)}}]$\n",
    "\n",
    "$f_{\\theta}(x^{(0)}) = [\\hat{z_0^{(2)}}, \\hat{z_1^{(2)}}, \\hat{z_2^{(2)}}, \\hat{z_3^{(2)}}, \\hat{z_4^{(2)}}, \\hat{z_5^{(2)}}, \\hat{z_6^{(2)}}]$\n",
    "\n",
    "If the optimization is good, the result should be:\n",
    "\n",
    "$\\hat{z_4^{(0)}} = 1, \\hat{z_5^{(1)}} = 5$ og $\\hat{z_6^{(2)}} = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3)**\n",
    "\n",
    "For the object function to be $\\mathcal{L}(\\theta, \\mathcal{D}) = 0$, the probability distribution must be given by:\n",
    "\n",
    "$\\hat{Y} = onehot(y) = \\begin{bmatrix}\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 1 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "In this case $\\hat{y}$ will be given by:\n",
    "\n",
    "$\\hat{y} := argmax(\\hat{Y}) = y$\n",
    "\n",
    "Then, $\\mathcal(L) = 0$ will be fulfilled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4)**\n",
    "\n",
    "The number of parameters is given by:\n",
    "\n",
    "$d(2m + n_{max} + L(4k + 2p))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5)**\n",
    "\n",
    "$X = onehot(x) = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "1\n",
    "\\end{bmatrix}, z_0 = W_Ex + [W_P]_{0:n} = \\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & \\alpha\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "0 \\\\\n",
    "1\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "1 \\\\\n",
    "0\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0 \\\\\n",
    "\\alpha\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "1 \\\\\n",
    "0\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "\\alpha\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$Z = softmax(\\begin{bmatrix}\n",
    "1\n",
    "\\alpha\n",
    "\\end{bmatrix}) = \\begin{bmatrix}\n",
    "\\frac{e^1}{e^1+1^{\\alpha}} \\\\\n",
    "\\frac{e^{\\alpha}}{e^1+e^{\\alpha}}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\hat{z} = 1 \\Rightarrow \\alpha > 1$ (when $\\alpha=1$, undefined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.0** Implementing the transformermodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** \n",
    "\n",
    "1) If the type of layer is identified as `LinearLayer` or `Attention`, `NeuralNetwork` will inherit `step_gd` from the `Layer` class. \n",
    "\n",
    "2) If the type of layer is identified as `EmbedPosition`, `NeuralNetwork` will inherit `step_gd` from the `EmbedPosition` class. \n",
    "\n",
    "3) If the type of layer is identified as `FeedForward`, `NeuralNetwork` will inherit `step_gd` from the `FeedForward` class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import *\n",
    "from layers import *\n",
    "from training import trainModel\n",
    "import numpy as np\n",
    "from data_generators import get_train_test_addition, get_train_test_sorting\n",
    "from training import *\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 5\n",
    "m = 2\n",
    "batchSize = 250\n",
    "batches = 10\n",
    "d = 10\n",
    "k = 5\n",
    "p = 15\n",
    "L = 2\n",
    "n_max = 2*r-1\n",
    "sigma = Relu\n",
    "\n",
    "data = get_train_test_sorting(r,m,batchSize, batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = EmbedPosition(n_max,m,d)\n",
    "att1 = Attention(d,k)\n",
    "att2 = Attention(d,k)\n",
    "ff1 = FeedForward(d,p)\n",
    "ff2 = FeedForward(d,p)\n",
    "un_embed = LinearLayer(d,m)\n",
    "softmax = Softmax()\n",
    "loss = CrossEntropy()\n",
    "\n",
    "att_ffd_list = []\n",
    "for layer in range(L):\n",
    "    att = Attention(d,k)\n",
    "    ff = FeedForward(d,p)\n",
    "    att_ffd_list.append(att)\n",
    "    att_ffd_list.append(ff)\n",
    "\n",
    "layers = [embed] + att_ffd_list + [un_embed] + [softmax]\n",
    "nn = NeuralNetwork(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterasjon  0  L =  0.6798913879467666  gradient =  0.03077889641111768\n",
      "Iterasjon  1  L =  0.6568162576830183  gradient =  0.030153246015312152\n",
      "Iterasjon  2  L =  0.630157397607699  gradient =  0.02952659140495251\n",
      "Iterasjon  3  L =  0.5994410899502028  gradient =  0.028962701470391514\n",
      "Iterasjon  4  L =  0.5653312968886912  gradient =  0.028568788223271305\n",
      "Iterasjon  5  L =  0.5298571987165105  gradient =  0.028468826141027564\n",
      "Iterasjon  6  L =  0.4957168946352953  gradient =  0.028729256976667224\n",
      "Iterasjon  7  L =  0.4655327450181218  gradient =  0.0292424043291102\n",
      "Iterasjon  8  L =  0.43981516669306664  gradient =  0.02974407690413431\n",
      "Iterasjon  9  L =  0.4172980032573517  gradient =  0.030066409894555397\n",
      "Iterasjon  10  L =  0.3968949903974736  gradient =  0.030316225679118246\n",
      "Iterasjon  11  L =  0.3780966296210862  gradient =  0.030608187705141936\n",
      "Iterasjon  12  L =  0.359192515550916  gradient =  0.031145834590071857\n",
      "Iterasjon  13  L =  0.3412807385297024  gradient =  0.031890315037114474\n",
      "Iterasjon  14  L =  0.3271538174713537  gradient =  0.032289949927825856\n",
      "Iterasjon  15  L =  0.31555969638417514  gradient =  0.032897433729808905\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m losses\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\petar\\Documents\\vitberkrigerene\\indmatprosjekt\\prosjekt_2_utlevert_kode\\training.py:25\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(nn, data, iterations, loss, m, slice_number, step_size)\u001b[0m\n\u001b[0;32m     23\u001b[0m     losses[j,i] \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mforward(Z,y[:,\u001b[38;5;241m-\u001b[39mslice_number:]) \u001b[38;5;66;03m#lagt til [:, -slice_number:]\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     dLdZ \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 25\u001b[0m     \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdLdZ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     nn\u001b[38;5;241m.\u001b[39mstep_adam(step_size, j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterasjon \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(j), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m L = \u001b[39m\u001b[38;5;124m\"\u001b[39m,np\u001b[38;5;241m.\u001b[39mmean(losses[j,:]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m gradient = \u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(dLdZ))\n",
      "File \u001b[1;32mc:\\Users\\petar\\Documents\\vitberkrigerene\\indmatprosjekt\\prosjekt_2_utlevert_kode\\neural_network.py:29\u001b[0m, in \u001b[0;36mNeuralNetwork.backward\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#reversed yields the layers in reversed order\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[1;32m---> 29\u001b[0m     grad \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad\n",
      "File \u001b[1;32mc:\\Users\\petar\\Documents\\vitberkrigerene\\indmatprosjekt\\prosjekt_2_utlevert_kode\\layers.py:419\u001b[0m, in \u001b[0;36mFeedForward.backward\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;124;03mInput:\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;124;03m    - grad of shape (b,d,n)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m#We use backward pass of the linear layers and activation.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m#Recall that the backward pass reverse the order of the layers. \u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m grad_feed_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;66;03m#Since forward pass is x + W2.T@Relu(W1@x)\u001b[39;00m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad \u001b[38;5;241m+\u001b[39m grad_feed_forward\n",
      "File \u001b[1;32mc:\\Users\\petar\\Documents\\vitberkrigerene\\indmatprosjekt\\prosjekt_2_utlevert_kode\\layers.py:251\u001b[0m, in \u001b[0;36mLinearLayer.backward\u001b[1;34m(self, grad)\u001b[0m\n\u001b[0;32m    247\u001b[0m b \u001b[38;5;241m=\u001b[39m grad\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m#Compute gradient (average over B batches) of loss wrt weight w: \u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m#dL/dw = (1/B)*sum_b^B (grad_b@x_b^T)\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbon,bdn->od\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m/\u001b[39mb\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m#Return gradient of loss wrt input of layer\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;66;03m#dL/dw = w@grad.T\u001b[39;00m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mod,bon->bdn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m],grad, optimize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\petar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\einsumfunc.py:1419\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[0;32m   1416\u001b[0m     right_pos\u001b[38;5;241m.\u001b[39mappend(input_right\u001b[38;5;241m.\u001b[39mfind(s))\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;66;03m# Contract!\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m new_view \u001b[38;5;241m=\u001b[39m \u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtmp_operands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mleft_pos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mright_pos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;66;03m# Build a new view if needed\u001b[39;00m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (tensor_result \u001b[38;5;241m!=\u001b[39m results_index) \u001b[38;5;129;01mor\u001b[39;00m handle_out:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mtensordot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\petar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\numeric.py:1138\u001b[0m, in \u001b[0;36mtensordot\u001b[1;34m(a, b, axes)\u001b[0m\n\u001b[0;32m   1136\u001b[0m at \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mtranspose(newaxes_a)\u001b[38;5;241m.\u001b[39mreshape(newshape_a)\n\u001b[0;32m   1137\u001b[0m bt \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mtranspose(newaxes_b)\u001b[38;5;241m.\u001b[39mreshape(newshape_b)\n\u001b[1;32m-> 1138\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39mreshape(olda \u001b[38;5;241m+\u001b[39m oldb)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = trainModel(nn,data,100,loss, m, r, 0.001)\n",
    "losses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1cb0218e8b0>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "len(losses)\n",
    "print(losses.shape)\n",
    "plt.semilogy(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DO NOT RUN IF NOT NEW TRAINED MODEL\n",
    "# with open(\"sortingTrained_v1\", 'wb') as f:\n",
    "    # pickle.dump(nn, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"savedObject\", 'rb') as f:\n",
    "     #nn2 = pickle.load(f)\n",
    "\n",
    "#type(nn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(250, 5)\n",
      "(250, 5)\n",
      "(250, 1)\n",
      "1\n",
      "(250, 6)\n",
      "(250, 6)\n",
      "(250, 1)\n",
      "2\n",
      "(250, 7)\n",
      "(250, 7)\n",
      "(250, 1)\n",
      "3\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 1)\n",
      "4\n",
      "(250, 9)\n",
      "(250, 9)\n",
      "(250, 1)\n"
     ]
    }
   ],
   "source": [
    "# with open(\"sortingTrained_v1\", \"rb\") as f:\n",
    "#     nn = pickle.load(f)\n",
    "\n",
    "y_pred = predict(nn, data['x_test'], r, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 1. 1. 1.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1. 1.]\n",
      "  [0. 0. 0. 1. 1.]\n",
      "  [0. 0. 1. 1. 1.]]]\n",
      "\n",
      "[[[0. 0. 1. 1. 1.]\n",
      "  [0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1. 1.]\n",
      "  [0. 0. 0. 1. 1.]\n",
      "  [0. 0. 1. 1. 1.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print()\n",
    "print(data['y_test'])\n",
    "np.count_nonzero(np.count_nonzero(y_pred == data['y_test'], axis=2) == y_pred.shape[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 7\n",
    "m = 5\n",
    "batchSize = 250\n",
    "batches = 10\n",
    "iterations = 100\n",
    "d = 20\n",
    "k = 10\n",
    "p = 25\n",
    "L = 2\n",
    "n_max = 2*r-1\n",
    "sigma = Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_train_test_sorting(r,m,batchSize, batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = EmbedPosition(n_max,m,d)\n",
    "att1 = Attention(d,k)\n",
    "att2 = Attention(d,k)\n",
    "\n",
    "ff1 = FeedForward(d,p)\n",
    "ff2 = FeedForward(d,p)\n",
    "\n",
    "un_embed = LinearLayer(d,m)\n",
    "softmax = Softmax()\n",
    "loss = CrossEntropy()\n",
    "\n",
    "nn = NeuralNetwork([embed,att1,ff1,att2, ff2, un_embed,softmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterasjon  0  L =  1.3180256645356145  gradient =  1.3605222554664682\n",
      "Iterasjon  1  L =  0.8029755259139074  gradient =  0.06154618129138519\n",
      "Iterasjon  2  L =  0.667250975058661  gradient =  0.04949780787098209\n",
      "Iterasjon  3  L =  0.5072564028433587  gradient =  0.04171710821499383\n",
      "Iterasjon  4  L =  0.33895783953587555  gradient =  0.03706066356420531\n",
      "Iterasjon  5  L =  0.22619707285197427  gradient =  0.026535261543089276\n",
      "Iterasjon  6  L =  0.1518116783863584  gradient =  0.01877311459919807\n",
      "Iterasjon  7  L =  0.10090941903367305  gradient =  0.020665271450939694\n",
      "Iterasjon  8  L =  0.06117139354637643  gradient =  0.017002306628716556\n",
      "Iterasjon  9  L =  0.0415024979300117  gradient =  0.01417552459519387\n",
      "Iterasjon  10  L =  0.026955114252082867  gradient =  0.013496925384970307\n",
      "Iterasjon  11  L =  0.017882066274081305  gradient =  0.013422863177501812\n",
      "Iterasjon  12  L =  0.013592010588700049  gradient =  0.013184414916341057\n",
      "Iterasjon  13  L =  0.00959545858703111  gradient =  0.013036842091560745\n",
      "Iterasjon  14  L =  0.007301502475513225  gradient =  0.013009653348738444\n",
      "Iterasjon  15  L =  0.006009369949758164  gradient =  0.012973813468684314\n",
      "Iterasjon  16  L =  0.005873924233109644  gradient =  0.013072541993283669\n",
      "Iterasjon  17  L =  0.005318683569327401  gradient =  0.013164510579015878\n",
      "Iterasjon  18  L =  0.003870981278336028  gradient =  0.012933707366023573\n",
      "Iterasjon  19  L =  0.003390873975882807  gradient =  0.01293774405863989\n",
      "Iterasjon  20  L =  0.002970875829712891  gradient =  0.012921170682557504\n",
      "Iterasjon  21  L =  0.0025034482323506605  gradient =  0.012903932108580509\n",
      "Iterasjon  22  L =  0.0022824714371413634  gradient =  0.0129021560074658\n",
      "Iterasjon  23  L =  0.0020210825333771064  gradient =  0.012896708921371253\n",
      "Iterasjon  24  L =  0.0018845565349152795  gradient =  0.012895319173808727\n",
      "Iterasjon  25  L =  0.0017217902568510662  gradient =  0.012890510484606982\n",
      "Iterasjon  26  L =  0.0016003835582656827  gradient =  0.012888933009817152\n",
      "Iterasjon  27  L =  0.001494267153284519  gradient =  0.012886963478114057\n",
      "Iterasjon  28  L =  0.0014013357028983234  gradient =  0.012885808367653701\n",
      "Iterasjon  29  L =  0.0013133084273750182  gradient =  0.012884171675389777\n",
      "Iterasjon  30  L =  0.001238709681154568  gradient =  0.012883234542352271\n",
      "Iterasjon  31  L =  0.0011736719504077695  gradient =  0.012882090055701817\n",
      "Iterasjon  32  L =  0.0011093894544362008  gradient =  0.012881269978761739\n",
      "Iterasjon  33  L =  0.0010511301204794742  gradient =  0.012880630366191546\n",
      "Iterasjon  34  L =  0.000995820690085481  gradient =  0.01288024518528979\n",
      "Iterasjon  35  L =  0.0009428805776449769  gradient =  0.012879965685476604\n",
      "Iterasjon  36  L =  0.0008894750102233191  gradient =  0.012879587042390658\n",
      "Iterasjon  37  L =  0.0008376804553336606  gradient =  0.012878883136491447\n",
      "Iterasjon  38  L =  0.0007948158164672936  gradient =  0.012878260923058148\n",
      "Iterasjon  39  L =  0.0007630914186903659  gradient =  0.01287780974222269\n",
      "Iterasjon  40  L =  0.0007377348719122875  gradient =  0.012877452577127994\n",
      "Iterasjon  41  L =  0.0007127914097861859  gradient =  0.012877109075238832\n",
      "Iterasjon  42  L =  0.0006861587730696312  gradient =  0.012876928657551707\n",
      "Iterasjon  43  L =  0.0006595020235065096  gradient =  0.012876877529473195\n",
      "Iterasjon  44  L =  0.0006280645316205194  gradient =  0.012876759285639049\n",
      "Iterasjon  45  L =  0.0005965058651126124  gradient =  0.012876452752273355\n",
      "Iterasjon  46  L =  0.0005692138578100761  gradient =  0.012876148178478725\n",
      "Iterasjon  47  L =  0.0005503626816130199  gradient =  0.012875997983445301\n",
      "Iterasjon  48  L =  0.0005203649796236278  gradient =  0.012875811248661646\n",
      "Iterasjon  49  L =  0.0004907288213313062  gradient =  0.012875696391560972\n",
      "Iterasjon  50  L =  0.00046446705500640306  gradient =  0.012875529040534843\n",
      "Iterasjon  51  L =  0.0004361263063483332  gradient =  0.012875521922728766\n",
      "Iterasjon  52  L =  0.00040705959814669437  gradient =  0.012875256706934976\n",
      "Iterasjon  53  L =  0.0003793267432449677  gradient =  0.012875058613495813\n",
      "Iterasjon  54  L =  0.0003577094485710308  gradient =  0.012874775593150317\n",
      "Iterasjon  55  L =  0.00034038702364072804  gradient =  0.012874623029272716\n",
      "Iterasjon  56  L =  0.0003237220652810357  gradient =  0.012874501811671329\n",
      "Iterasjon  57  L =  0.00030649498881185177  gradient =  0.012874377978031525\n",
      "Iterasjon  58  L =  0.0002913591172075379  gradient =  0.012874280271468601\n",
      "Iterasjon  59  L =  0.00027660278351209204  gradient =  0.012874163912447502\n",
      "Iterasjon  60  L =  0.0002650082067874707  gradient =  0.012874039786069134\n",
      "Iterasjon  61  L =  0.00025572225526857977  gradient =  0.01287394010426177\n",
      "Iterasjon  62  L =  0.00024819682610594006  gradient =  0.012873847706556156\n",
      "Iterasjon  63  L =  0.0002402463669905107  gradient =  0.012873773079302361\n",
      "Iterasjon  64  L =  0.00023110927902562318  gradient =  0.012873704753296947\n",
      "Iterasjon  65  L =  0.00022112376122020025  gradient =  0.01287363660872464\n",
      "Iterasjon  66  L =  0.00021054835462432116  gradient =  0.01287357395605488\n",
      "Iterasjon  67  L =  0.00019916170142572713  gradient =  0.01287353928891103\n",
      "Iterasjon  68  L =  0.00019103553263654974  gradient =  0.012873419786156179\n",
      "Iterasjon  69  L =  0.00018317371310977768  gradient =  0.012873326708927142\n",
      "Iterasjon  70  L =  0.00017638348403712384  gradient =  0.012873236803306225\n",
      "Iterasjon  71  L =  0.00016893128198658218  gradient =  0.012873176258722023\n",
      "Iterasjon  72  L =  0.0001612226831383032  gradient =  0.01287312583475272\n",
      "Iterasjon  73  L =  0.0001548157841358167  gradient =  0.012873073415079855\n",
      "Iterasjon  74  L =  0.0001497949612404465  gradient =  0.012873029740963167\n",
      "Iterasjon  75  L =  0.00014539253127469673  gradient =  0.012872984887263765\n",
      "Iterasjon  76  L =  0.0001406610606052273  gradient =  0.01287294208041331\n",
      "Iterasjon  77  L =  0.00013592483890357274  gradient =  0.012872894177644362\n",
      "Iterasjon  78  L =  0.00013141246606818713  gradient =  0.012872849786735962\n",
      "Iterasjon  79  L =  0.00012714807272990494  gradient =  0.012872812526859784\n",
      "Iterasjon  80  L =  0.00012309989776071033  gradient =  0.012872778871224087\n",
      "Iterasjon  81  L =  0.00011942086701450781  gradient =  0.012872746235451121\n",
      "Iterasjon  82  L =  0.00011595053292019644  gradient =  0.012872713033759817\n",
      "Iterasjon  83  L =  0.00011246810638017987  gradient =  0.01287268000022065\n",
      "Iterasjon  84  L =  0.00010915559136145704  gradient =  0.012872648784354469\n",
      "Iterasjon  85  L =  0.00010595843220922382  gradient =  0.01287261839421967\n",
      "Iterasjon  86  L =  0.00010287231629157422  gradient =  0.012872591843681835\n",
      "Iterasjon  87  L =  9.998444054918601e-05  gradient =  0.012872565750111392\n",
      "Iterasjon  88  L =  9.725416327320075e-05  gradient =  0.012872540175498687\n",
      "Iterasjon  89  L =  9.45492798893366e-05  gradient =  0.012872514514297112\n",
      "Iterasjon  90  L =  9.188350778369754e-05  gradient =  0.012872490697195605\n",
      "Iterasjon  91  L =  8.941161644592132e-05  gradient =  0.012872468378476212\n",
      "Iterasjon  92  L =  8.703013233958714e-05  gradient =  0.012872446243380305\n",
      "Iterasjon  93  L =  8.470707826496111e-05  gradient =  0.012872424977791518\n",
      "Iterasjon  94  L =  8.242303354407017e-05  gradient =  0.012872404142831638\n",
      "Iterasjon  95  L =  8.029496170105397e-05  gradient =  0.012872384313407164\n",
      "Iterasjon  96  L =  7.825283398680298e-05  gradient =  0.01287236667673534\n",
      "Iterasjon  97  L =  7.623666245698836e-05  gradient =  0.01287234889530398\n",
      "Iterasjon  98  L =  7.43390231711421e-05  gradient =  0.012872331182854801\n",
      "Iterasjon  99  L =  7.245339396410933e-05  gradient =  0.012872314918892748\n"
     ]
    }
   ],
   "source": [
    "losses = trainModel(nn,data, iterations, loss, m, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(250, 7)\n",
      "(250, 7)\n",
      "(250, 1)\n",
      "1\n",
      "(250, 8)\n",
      "(250, 8)\n",
      "(250, 1)\n",
      "2\n",
      "(250, 9)\n",
      "(250, 9)\n",
      "(250, 1)\n",
      "3\n",
      "(250, 10)\n",
      "(250, 10)\n",
      "(250, 1)\n",
      "4\n",
      "(250, 11)\n",
      "(250, 11)\n",
      "(250, 1)\n",
      "5\n",
      "(250, 12)\n",
      "(250, 12)\n",
      "(250, 1)\n",
      "6\n",
      "(250, 13)\n",
      "(250, 13)\n",
      "(250, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(nn, data['x_test'], r, m)\n",
    "np.count_nonzero(np.count_nonzero(y_pred == data['y_test'], axis=2) == y_pred.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 250\n",
    "batches = 20\n",
    "d = 30\n",
    "k=20\n",
    "p=40\n",
    "L=3\n",
    "m=10\n",
    "n_max = 2*2 + 3\n",
    "\n",
    "data =get_train_test_addition(2,batch_size,20)\n",
    "loss = CrossEntropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "\n",
    "embed = EmbedPosition(n_max - 1,m,d)\n",
    "layers.append(embed)\n",
    "for i in range(L):\n",
    "    att1 = Attention(d,k)\n",
    "    ff1 = FeedForward(d,p)\n",
    "\n",
    "    layers.append(att1)\n",
    "    layers.append(ff1)\n",
    "\n",
    "\n",
    "un_embed = LinearLayer(d,m)\n",
    "layers.append(un_embed)\n",
    "softmax = Softmax()\n",
    "layers.append(softmax)\n",
    "\n",
    "nn = NeuralNetwork(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterasjon  0  L =  0.2325853672448957  gradient =  115470.05383792659\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrainModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#her kjem da dimensjonsfeil må sjekkes ut\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\petar\\Documents\\vitberkrigerene\\indmatprosjekt\\prosjekt_2_utlevert_kode\\training.py:20\u001b[0m, in \u001b[0;36mtrainModel\u001b[1;34m(nn, data, iterations, loss, m, slice_number, step_size)\u001b[0m\n\u001b[0;32m     17\u001b[0m y \u001b[38;5;241m=\u001b[39m ys[i]\n\u001b[0;32m     19\u001b[0m X \u001b[38;5;241m=\u001b[39m onehot(x,m)\n\u001b[1;32m---> 20\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m#losses[j,i] = loss.forward(Z, y)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m losses[j,i] \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mforward(Z,y[:,\u001b[38;5;241m-\u001b[39mslice_number:]) \u001b[38;5;66;03m#lagt til [:, -slice_number:]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\petar\\Documents\\vitberkrigerene\\indmatprosjekt\\prosjekt_2_utlevert_kode\\neural_network.py:17\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m#Recursively perform forward pass from initial input x\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 17\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\petar\\Documents\\vitberkrigerene\\indmatprosjekt\\prosjekt_2_utlevert_kode\\layers.py:405\u001b[0m, in \u001b[0;36mFeedForward.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03mInput:\u001b[39;00m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;124;03m    - x of shape (b,d,n)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;124;03m (W1,W2 are p x d)\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m--> 405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\petar\\Documents\\vitberkrigerene\\indmatprosjekt\\prosjekt_2_utlevert_kode\\layers.py:237\u001b[0m, in \u001b[0;36mLinearLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m#Return output of layer\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m#y = w@x\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mod,bdn->bon\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\petar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\einsumfunc.py:1419\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[0;32m   1416\u001b[0m     right_pos\u001b[38;5;241m.\u001b[39mappend(input_right\u001b[38;5;241m.\u001b[39mfind(s))\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;66;03m# Contract!\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m new_view \u001b[38;5;241m=\u001b[39m \u001b[43mtensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtmp_operands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mleft_pos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mright_pos\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;66;03m# Build a new view if needed\u001b[39;00m\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (tensor_result \u001b[38;5;241m!=\u001b[39m results_index) \u001b[38;5;129;01mor\u001b[39;00m handle_out:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mtensordot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\petar\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\numeric.py:1136\u001b[0m, in \u001b[0;36mtensordot\u001b[1;34m(a, b, axes)\u001b[0m\n\u001b[0;32m   1133\u001b[0m newshape_b \u001b[38;5;241m=\u001b[39m (N2, \u001b[38;5;28mint\u001b[39m(multiply\u001b[38;5;241m.\u001b[39mreduce([bs[ax] \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m notin])))\n\u001b[0;32m   1134\u001b[0m oldb \u001b[38;5;241m=\u001b[39m [bs[axis] \u001b[38;5;28;01mfor\u001b[39;00m axis \u001b[38;5;129;01min\u001b[39;00m notin]\n\u001b[1;32m-> 1136\u001b[0m at \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewaxes_a\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewshape_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1137\u001b[0m bt \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mtranspose(newaxes_b)\u001b[38;5;241m.\u001b[39mreshape(newshape_b)\n\u001b[0;32m   1138\u001b[0m res \u001b[38;5;241m=\u001b[39m dot(at, bt)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = trainModel(nn,data, 150, loss, m, 3) #her kjem da dimensjonsfeil må sjekkes ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN IF NOT NEW TRAINED MODEL\n",
    "# with open(\"sortingTrained_v2\", 'wb') as f:\n",
    "    # pickle.dump(nn, f)\n",
    "\n",
    "with open(\"addition_nn\", \"wb\") as f:\n",
    "    pickle.dump(nn,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(250, 4)\n",
      "(250, 4)\n",
      "(250, 1)\n",
      "1\n",
      "(250, 5)\n",
      "(250, 5)\n",
      "(250, 1)\n",
      "2\n",
      "(250, 6)\n",
      "(250, 6)\n",
      "(250, 1)\n",
      "Riktige:250\n",
      "Y:\n",
      "[[0. 7. 7.]\n",
      " [1. 2. 2.]\n",
      " [0. 8. 5.]\n",
      " [1. 8. 0.]\n",
      " [0. 8. 6.]\n",
      " [0. 9. 5.]\n",
      " [1. 5. 0.]\n",
      " [0. 4. 9.]\n",
      " [0. 9. 9.]\n",
      " [1. 7. 2.]]\n",
      "fasit\n",
      "[[0 7 7]\n",
      " [1 2 2]\n",
      " [0 8 5]\n",
      " [1 8 0]\n",
      " [0 8 6]\n",
      " [0 9 5]\n",
      " [1 5 0]\n",
      " [0 4 9]\n",
      " [0 9 9]\n",
      " [1 7 2]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(nn, data['x_test'], 3, m)\n",
    "print(f\"Riktige:{np.count_nonzero(np.count_nonzero(y_pred[:,:,::-1] == data['y_test'], axis=2) == y_pred.shape[-1])}\")\n",
    "# print(\"X:\")\n",
    "# print(data['x_test'][0][:10])\n",
    "print(\"Y:\")\n",
    "print((y_pred[0][:10,::-1]))\n",
    "print(\"fasit\")\n",
    "print(data['y_test'][0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
