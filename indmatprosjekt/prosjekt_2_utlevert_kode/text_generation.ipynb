{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import onehot\n",
    "from data_generators import text_to_training_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate(net,start_idx,m,n_max,n_gen):\n",
    "    \n",
    "    #We will concatenate all generated integers (idx) in total_seq_idx\n",
    "    total_seq_idx = start_idx\n",
    "\n",
    "    n_total = total_seq_idx.shape[-1]\n",
    "    slice = 0\n",
    "\n",
    "    x_idx = start_idx\n",
    "\n",
    "    while n_total < n_gen:\n",
    "        n_idx = x_idx.shape[-1]\n",
    "        X = onehot(x_idx,m)\n",
    "\n",
    "        #probability distribution over m characters\n",
    "        Z = net.forward(X)\n",
    "\n",
    "        #selecting the last column of Z (distribution over final character)\n",
    "        hat_Y = Z[0,:,-1]\n",
    "\n",
    "        #sampling from the multinomial distribution\n",
    "        #we do this instead of argmax to introduce some randomness\n",
    "        #avoiding getting stuck in a loop\n",
    "        y_idx = np.argwhere(np.random.multinomial(1, hat_Y.T)==1)\n",
    "\n",
    "        if n_idx+1 > n_max:\n",
    "            slice = 1\n",
    "\n",
    "        #we add the new hat_y to the existing sequence\n",
    "        #but we make sure that we only keep the last n_max elements\n",
    "        x_idx = np.concatenate([x_idx[:,slice:],y_idx],axis=1)\n",
    "\n",
    "        #we concatenate the new sequence to the total sequence\n",
    "        total_seq_idx = np.concatenate([total_seq_idx,y_idx],axis=1)\n",
    "\n",
    "        n_total = total_seq_idx.shape[-1]\n",
    "\n",
    "    return total_seq_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 80\n",
    "n_max = 50\n",
    "p = 100\n",
    "k = 25\n",
    "L = 2\n",
    "\n",
    "text =  open('input.txt', 'r').read()\n",
    "data,idx_to_text,text_to_idx, m = text_to_training_data(n_max,text,num_batches=20,batch_size=50)\n",
    "\n",
    "\n",
    "print(\"We will train on %d batches of size %d\" % (len(data['x_train']),len(data['x_train'][0])))\n",
    "print(\"Each sequence has length %d\" % n_max)\n",
    "\n",
    "print(\"Example of a sequence (chars): \\n\")\n",
    "print(''.join([idx_to_text[i] for i in data['x_train'][0][0]]))\n",
    "\n",
    "print(\"\\nExample of a sequence (idx): \\n\")\n",
    "print(data['x_train'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import *\n",
    "from neural_network import NeuralNetwork\n",
    "\n",
    "layers = []\n",
    "net = NeuralNetwork(layers)\n",
    "loss = CrossEntropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "Insert you code for training the neural network here\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can now generate text from an initial string\n",
    "start_text = \"Thou shall not\"\n",
    "start_idx = text_to_idx(start_text,text_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#length of the total text sequence we want to generate\n",
    "n_gen = 10*n_max\n",
    "\n",
    "generated_idx = generate(net,start_idx,m,n_max,n_gen)\n",
    "\n",
    "text = idx_to_text(generated_idx,idx_to_text)\n",
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
