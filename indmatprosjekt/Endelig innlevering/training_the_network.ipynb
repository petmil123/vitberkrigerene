{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3.1** Training the transformermodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing `trainModel`, we can now use it to optimize the parameters. First we train for `r=5, m=2, samples=250, batches=10, d=10, k=5, p=15, L=2, n_max=2r-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neural_network import *\n",
    "from layers import *\n",
    "from training import trainModel\n",
    "import numpy as np\n",
    "from data_generators import get_train_test_addition, get_train_test_sorting\n",
    "from training import *\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 5\n",
    "m = 2\n",
    "batchSize = 250\n",
    "batches = 10\n",
    "d = 10\n",
    "k = 5\n",
    "p = 15\n",
    "L = 2\n",
    "n_max = 2 * r - 1\n",
    "sigma = Relu\n",
    "\n",
    "data = get_train_test_sorting(r, m, batchSize, batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = EmbedPosition(n_max, m,d)\n",
    "att1 = Attention(d, k)\n",
    "att2 = Attention(d, k)\n",
    "ff1 = FeedForward(d, p)\n",
    "ff2 = FeedForward(d, p)\n",
    "un_embed = LinearLayer(d, m)\n",
    "softmax = Softmax()\n",
    "loss = CrossEntropy()\n",
    "\n",
    "att_ffd_list = []\n",
    "for layer in range(L):\n",
    "    att = Attention(d, k)\n",
    "    ff = FeedForward(d, p)\n",
    "    att_ffd_list.append(att)\n",
    "    att_ffd_list.append(ff)\n",
    "\n",
    "layers = [embed] + att_ffd_list + [un_embed] + [softmax]\n",
    "nn = NeuralNetwork(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = trainModel(nn, data, 100, loss, m, r, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sortingTrained1\", 'wb') as f:\n",
    "    pickle.dump(nn, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
